{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctzW-sMlA8rx",
        "outputId": "53d745cf-3a48-48d2-b47f-a1856c56f2d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/444.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.5/378.5 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain-core langchain-openai langchain_huggingface langchain-community langsmith"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-docling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McNTTm3ujZJD",
        "outputId": "065f615b-eda0-4ca5-b065-0ae68d4845ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qdrant-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtN3KaxxpwYo",
        "outputId": "677364ad-1b0e-4a4f-e727-f6f8b8f7b7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qdrant-client\n",
            "  Downloading qdrant_client-1.15.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (1.74.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.0.2)\n",
            "Collecting portalocker<4.0,>=2.7.0 (from qdrant-client)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (5.29.5)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.11.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Downloading qdrant_client-1.15.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, qdrant-client\n",
            "Successfully installed portalocker-3.2.0 qdrant-client-1.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sReCZNaMaow",
        "outputId": "a95e1720-8280-434f-f33f-e2201c5afdef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "from IPython.display import display, Markdown\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from qdrant_client import QdrantClient\n",
        "from pprint import pprint\n",
        "from langchain_docling import DoclingLoader\n",
        "from langchain_docling.loader import ExportType\n",
        "from transformers import AutoTokenizer\n",
        "from langchain_huggingface import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "A4Ak2Pw2Cv7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingfacehub_api_token = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "GvjR6X-y4a0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Qdrant_api_key = userdata.get('api_key')"
      ],
      "metadata": {
        "id": "Hco-CkLALra7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatHuggingFace(\n",
        "  llm=HuggingFaceEndpoint(\n",
        "      repo_id=\"Qwen/Qwen3-Coder-480B-A35B-Instruct\",\n",
        "      provider=\"together\",\n",
        "      huggingfacehub_api_token=huggingfacehub_api_token,\n",
        "      task=\"conversational\"\n",
        "  )\n",
        ")"
      ],
      "metadata": {
        "id": "RvYNVzxeh8z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "4CppKbIu6bum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url='/content/transcript-20210724 (2).pdf'\n",
        "question=\"Return to me list for all courses in Main Specialization Requirements with his hours and grade \""
      ],
      "metadata": {
        "id": "9IExmcqY9FYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(url):\n",
        "  FILE_PATH = url\n",
        "  loader = DoclingLoader(file_path=FILE_PATH, export_type= ExportType.MARKDOWN).load()\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "  text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
        "      tokenizer, chunk_size=300, chunk_overlap=20\n",
        "  )\n",
        "  normal_chunks = text_splitter.create_documents([loader[0].model_dump()['page_content']], metadatas=[loader[0].model_dump()['metadata']])\n",
        "  return normal_chunks"
      ],
      "metadata": {
        "id": "vb3zSx5eAQw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Database"
      ],
      "metadata": {
        "id": "kn717-YU6faB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Hybrid_search(normal_chunks):\n",
        "    model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "\n",
        "    embedding_llm = HuggingFaceEmbeddings(model_name=model_name)\n",
        "    qdrant_store = Qdrant.from_documents(\n",
        "    documents=normal_chunks,\n",
        "    embedding=embedding_llm,\n",
        "    url=\"https://3464a78e-425b-4e6b-bc10-5b0333dc9ad1.us-east4-0.gcp.cloud.qdrant.io:6333\",\n",
        "    api_key=Qdrant_api_key,\n",
        "    collection_name=\"my_collection\",\n",
        "    force_recreate=True # Add this line to recreate the collection if it doesn't exist\n",
        "    )\n",
        "    dense_retriever = qdrant_store.as_retriever(\n",
        "        search_kwargs={\n",
        "            \"k\": 8,                  # top-k\n",
        "            \"score_threshold\": 0.25  # filter low scores\n",
        "        }\n",
        "    )\n",
        "    bm25_retriever = BM25Retriever.from_documents(normal_chunks)\n",
        "    bm25_retriever.k = 8\n",
        "    hybrid_retriever = EnsembleRetriever(\n",
        "        retrievers=[bm25_retriever, dense_retriever],\n",
        "        weights=[0.4, 0.6]\n",
        "    )\n",
        "    return hybrid_retriever"
      ],
      "metadata": {
        "id": "8LH2eKKEkTeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent"
      ],
      "metadata": {
        "id": "uyVWczri7KP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_model(question,hybrid_retriever):\n",
        "    qna_template = \"\\n\".join([\"\"\"\n",
        "              You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
        "              If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
        "              Question: {question}\n",
        "              Context: {context}\n",
        "              Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    ])\n",
        "\n",
        "    qna_prompt = PromptTemplate(\n",
        "        template=qna_template,\n",
        "        input_variables=['context', 'question'],\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "\n",
        "    stuff_chain = create_stuff_documents_chain(llm, prompt=qna_prompt)\n",
        "    question=question\n",
        "    retreive_doc= hybrid_retriever.get_relevant_documents(question)\n",
        "    answer = stuff_chain.invoke(\n",
        "        {\n",
        "            \"context\": retreive_doc,\n",
        "            \"question\": question\n",
        "        }\n",
        "    )\n",
        "    return answer"
      ],
      "metadata": {
        "id": "wRBZ7kWG7974"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk=prepare_data(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFI6P7Pb-N8q",
        "outputId": "495419c3-dd4a-4552-c797-56f0bab330ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 353, which is longer than the specified 300\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 537, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 483, which is longer than the specified 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_retriever=Hybrid_search(chunk)"
      ],
      "metadata": {
        "id": "9wk00ql3-ewt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=call_model(question,hybrid_retriever)"
      ],
      "metadata": {
        "id": "oguM0_UaADCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "EINL3tS_AKDT",
        "outputId": "c18d16ce-b2e8-41e7-ffc5-70cf35ec7dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here is the list of courses in the Main Specialization Requirements with their hours and grades:\n\n**Compulsory Subjects (39 hours):**\n- Artificial Intelligence (AI 310): 3 hours, Grade C+\n- Image Processing-1 (IT 441): 3 hours, Grade B+\n- Convex Optimization Theory (AI 320): 3 hours, Grade C+\n- Evolutionary Algorithm (AI 420): 3 hours, Grade C\n- Machine Learning (AI 330): 3 hours, Grade B+\n- Computational Intelligence (AI 430): 3 hours, Grade B+\n- Neural Networks & Deep Learning (AI 335): 3 hours, Grade A+\n- Natural Language Processing (AI 360): 3 hours, Grade B\n- Advanced Machine Learning (AI 370): 3 hours, Grade B+\n- Big Data Technologies (IS 365): 3 hours, Grade C+\n- Natural Language Understanding (AI 460): 3 hours, Grade A\n- Project (AI 0): 6 hours, Grade A+\n\n**Elective Subjects (21 hours):**\n- Microprocessors (IT 312): 3 hours\n- Cryptography (CS 480): 3 hours\n- Parallel Processing and High Performance Computing (CS 471): 3 hours, Grade A\n- Distributed Systems and Cloud Computing (CS 460): 3 hours, Grade A+\n- Embedded Systems (IT 414): 3 hours\n- Advanced Algorithms (CS 416): 3 hours\n- Digital Signal Processing (IT 341): 3 hours\n- Human Computer Interaction (AI 380): 3 hours\n- Bioinformatics (AI 490): 3 hours\n- Speech Processing (IT 443): 3 hours, Grade B\n- Computer Vision (IT 444): 3 hours, Grade A+\n- Introduction to Data Science (IS 360): 3 hours, Grade B+\n- Knowledge Representation (AI 457): 3 hours\n- Database Systems-2 (IS 312): 3 hours, Grade B\n- Robotics (IT 415): 3 hours, Grade B\n- Spoken Language Processing (AI 435): 3 hours\n- Data Visualization (AI 350): 3 hours\n- Embedded Internet of Things System (IT 425): 3 hours\n- Selected Topics in Artificial Intelligence (AI 496): 3 hours"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Xx6BCeRFRZi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}